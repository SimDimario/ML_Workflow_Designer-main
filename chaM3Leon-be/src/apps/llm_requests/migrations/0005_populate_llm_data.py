# Generated by Django 5.2.6 on 2025-10-01 09:55

from django.db import migrations


def populate_llm_data(apps, schema_editor):
    """
    Popola il database con i provider e modelli LLM predefiniti
    """
    LLMProvider = apps.get_model('llm_requests', 'LLMProvider')
    LLMModel = apps.get_model('llm_requests', 'LLMModel')
    
    # Skip if data already exists
    if LLMProvider.objects.exists():
        return
    
    # Crea i provider
    providers_data = [
        {
            'name': 'openai',
            'display_name': 'OpenAI',
            'is_active': True
        },
        {
            'name': 'anthropic',
            'display_name': 'Anthropic',
            'is_active': True
        },
        {
            'name': 'gemini',
            'display_name': 'Google Gemini',
            'is_active': True
        }
    ]

    providers = {}
    for provider_data in providers_data:
        provider = LLMProvider.objects.create(**provider_data)
        providers[provider.name] = provider

    # Crea i modelli
    models_data = [
        # OpenAI Models
        {
            'provider': providers['openai'],
            'name': 'gpt-4o',
            'display_name': 'GPT-4o',
            'max_tokens': 4096,
            'supports_streaming': True,
            'is_active': True
        },
        {
            'provider': providers['openai'],
            'name': 'gpt-4o-mini',
            'display_name': 'GPT-4o Mini',
            'max_tokens': 16384,
            'supports_streaming': True,
            'is_active': True
        },
        {
            'provider': providers['openai'],
            'name': 'gpt-3.5-turbo',
            'display_name': 'GPT-3.5 Turbo',
            'max_tokens': 4096,
            'supports_streaming': True,
            'is_active': True
        },
        
        # Anthropic Models
        {
            'provider': providers['anthropic'],
            'name': 'claude-3-5-sonnet-20241022',
            'display_name': 'Claude 3.5 Sonnet',
            'max_tokens': 8192,
            'supports_streaming': True,
            'is_active': True
        },
        {
            'provider': providers['anthropic'],
            'name': 'claude-3-haiku-20240307',
            'display_name': 'Claude 3 Haiku',
            'max_tokens': 4096,
            'supports_streaming': True,
            'is_active': True
        },
        
        # Gemini Models
        {
            'provider': providers['gemini'],
            'name': 'gemini-2.5-flash',
            'display_name': 'Gemini 2.5 Flash',
            'max_tokens': 8192,
            'supports_streaming': False,
            'is_active': True
        },
        {
            'provider': providers['gemini'],
            'name': 'gemini-1.5-pro',
            'display_name': 'Gemini 1.5 Pro',
            'max_tokens': 32768,
            'supports_streaming': False,
            'is_active': True
        },
    ]

    for model_data in models_data:
        LLMModel.objects.create(**model_data)


def reverse_populate_llm_data(apps, schema_editor):
    """
    Rimuove i dati LLM creati dalla migrazione
    """
    LLMProvider = apps.get_model('llm_requests', 'LLMProvider')
    LLMModel = apps.get_model('llm_requests', 'LLMModel')
    
    # Elimina tutti i modelli e provider
    LLMModel.objects.all().delete()
    LLMProvider.objects.all().delete()


class Migration(migrations.Migration):

    dependencies = [
        ('llm_requests', '0004_alter_workflowfileanalysis_workflow_content_and_more'),
    ]

    operations = [
        migrations.RunPython(
            populate_llm_data,
            reverse_populate_llm_data,
            elidable=True,  # Questa migrazione può essere omessa se ci sono già dati
        ),
    ]
